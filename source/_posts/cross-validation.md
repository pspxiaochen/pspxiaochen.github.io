---
title: 机器学习之交叉验证
date: 2018-06-29 10:27:00
categories:
  - 机器学习
copyright: true
tags:
  - 交叉验证  
description: 昨天面试的不太好，面试官问到了几种交叉验证可以解决的问题，没有答上来，今天来总结一下。
---

# 交叉验证的基本思想
&emsp;&emsp; 交叉验证的基本想法是重复的使用数据；把给定数据进行切分，将切分的数据集组合为训练集与测试集，再次基础上反复地进行训练、测试、以及模型选择。
##简单的交叉验证
1、首先随机得将已给数据分为两部分，一部分作为训练集，一部分作为测试集。（一般是73分）
2、然后用训练集在各种条件下（比如不同的参数）训练模型，从而得到不同的模型；
3、在测试集上评价各个模型的测试误差，选出测试误差最小的模型。
优点：由于测试集和训练集是分开的，就避免了过拟合现象

##k折交叉验证
1.首先将训练数据平均切分成k份，每一份互不相交且大小一样。
2.用k-1个子集进行训练模型，用余下的那一个作为预测。
3.将2这一过程对可能的k种选择重复进行。
4.最后选出k次测评中平均测试误差最小的模型。
优点：这个方法充分利用了所有样本。但计算比较繁琐，需要训练k次，测试k次。

##留一法
留一法就是每次只留下一个样本做测试集，其它样本做训练集，如果有k个样本，则需要训练k次，测试k次。
优点：留一发计算最繁琐，但样本利用率最高。适合于小样本的情况。